---
title: "Litigant Framing Data"
author: "Amanda Konet and Sarah Torrence"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F, error = F)

# Box access
library(boxr)
box_auth()

# data manip?
library(tidyverse)

# parallel processing
library(R.utils)
library(doParallel)
```

# Purpose

There are ~40 folders in Supreme Court > Sup Ct - Abortion Cases. For each litigant file (NOT denoted by files with "amicus”, “amici”, “decision”, “reply”, “appendix”, and “oral” in the file name), copy the file ID, file name, case name, and file text into a CSV.


# 1. Obtain file names and IDs

Set working directory to  files folder

```{r}
box_setwd("6932017842")
```

Get IDs of all the case folders

```{r}
# Get the IDs of all the case folders 
case_folders <- box_ls() %>%
  as.data.frame() %>% 
  filter(type == "folder") %>% 
  rename(case = name)

case_folders %>% head(1)
```

For all of the folders, retrieve every file name and ID. 

```{r}
# number of cores available
n_cores <- detectCores() - 1
registerDoParallel(n_cores)

# given a df of ids for SC folder, extract names and ids of all files in case folder
# then, save only the name and id of the decision file
all_file_names <- function(case_folder_ids) {
  
  # get info for all files contained in each case folder
  # stored in a list of lists
  cases_ids_list <- mclapply(case_folder_ids$id,
                                box_ls,
                                mc.cores = n_cores)
  
  # convert to list of df
  cases_ids_list <- map(cases_ids_list, as.data.frame)
  
  # get name of folder (this is case name)
  # NOTE path col is Amicus IV/data/amicus files/case name - we want the last bit "case name"
  cases_ids_list <- lapply(cases_ids_list, function(x) transform(x, case = sub(".*/", "", path)))
  
  print("Created list of dfs; each element is a case folder")
  
  # create iterator that will go through list element by element
  it <- iter(cases_ids_list, by = "row")
  
  # in each case folder, grab the name and id of the decision file
  file_ids <-
    foreach(i = it,
            .combine = rbind,
            .inorder = F) %dopar% {
              i %>%
                filter(!grepl("amicus|amici|decision|reply|appendix|oral", name, ignore.case = T)) %>%
                select(case, name, id, type)
            }
  print("Obtained litigant file ids")
  
  return(file_ids)
}

# run the function for Abortion and Sex Discrim folders
litigant_file_ids <- all_file_names(case_folders)

doParallel::stopImplicitCluster()
```


Check what we have - count of amicus briefs by case for manual comparison

```{r}
# save this file to data > processed amicus files
litigant_file_ids %>% 
  right_join(., case_folders, "case") %>% 
  group_by(case) %>% 
  summarize(n = sum(!grepl("amicus|amici|decision|reply|appendix|oral", name, ignore.case = T))) %>% 
  arrange(case)
```

Save list of litigant file IDs on Box

```{r}
#litigant_file_ids %>% 
  # only files
#  filter(type == "file", name != ".DS_Store") %>% 
  # add matching case
#  right_join(., case_folders, "case") %>% 
  # rename ids/type
#  select(-id.y, -type.y) %>% 
#  rename(id = id.x, type = type.x) %>% 
  # name lower
#  mutate(file_type = tolower(sub(".*\\.", "", name))) %>% 
  # select final vars
#  select(case, id, name, type) %>% 
#  arrange(case) %>% 
#  box_write(., "litigant-brief-file-ids.xlsx", dir_id = "162588272045")
```


# 2. Scrape Text

Obtain the raw text from each amicus brief. Note that we have two file types here that we want: DOCX & PDF. All other duplicate folders and extra types can be filtered out.

Add file extension as col

```{r}
litigant_file_ids <- litigant_file_ids %>% 
  mutate(file_type = tolower(sub(".*\\.", "", name))) 
litigant_file_ids %>% group_by(file_type) %>% summarize(n = n())
```
Filter for only pdf and docx files 

```{r}
litigant_file_ids <- litigant_file_ids %>% filter(file_type == 'docx' | file_type == 'pdf')

# filter for only briefs that need to be re-pulled
litigant_file_ids <- litigant_file_ids %>% 
  filter(id %in% c("955405762992", "955404304453", "955405038378", "955401734984", "56699188926", "56701967150","56698341318"))
```

Read text

```{r}
# create iterator 
itd <- iter(litigant_file_ids, by = "row")

# set up cluster
n_cores <- detectCores() - 1
registerDoParallel(n_cores)

# get text of cases in parallel
litigant_txt <- foreach(i = itd, .inorder = F, .combine = rbind) %dopar% {
  
  # get id and file type of current file
  id <- i %>% pull(id)
  type <- i %>% pull(file_type)
  
  # grab case and brief names
  case <- i %>% pull(case)
  brief <- i %>% pull(name)
  
  if (type == "pdf") {
    # is the file a PDF
    
    txt <- box_read(
      file_id = id,
      read_fun = function(x)
        pdftools::pdf_text(x) %>%
        readr::read_lines()
    )
    
  } else if (type == "docx") {
    # is the file a DOCX
    
    txt <- box_read(
      file_id = id,
      read_fun = function(x)
        textreadr::read_docx(x)
    )
    
  }  else {
    txt <- box_read(
      file_id = id,
      read_fun = function(x)
        textreadr::read_document(x)
    )
    
  }

  # grab text and concat to string
  # txt <- box_read(
  #  file_id = id,
  #  read_fun = function(x)
  #    textreadr::read_document(x)
  # )
  
  # concatenate to string
  txt_full <- paste(txt, sep = ' ', collapse = ' ')
  
  # add row
  data.frame(case, brief, id, txt_full)
}

doParallel::stopImplicitCluster()
```



Read in list of litigant file IDs, drop those that are marked "drop"

```{r}
drop_file_ids <- box_read("955323576728") %>% 
  filter(drop == 1, !is.na(id)) %>% 
  select(id)

litigant_txt <- litigant_txt %>% filter(!(id %in% drop_file_ids$id))
```

Check that our files contain "summary of (the) argument: this is the phrase that indicates the start of the text we want to analyze.

```{r}
litigant_txt %>% 
   mutate(txt_full = str_squish(txt_full),
          summary = grepl("summary of argument|summary of the argument", txt_full, ignore.case = T)) %>%
   group_by(summary) %>% 
   summarize(n=n())
```

Which files do not? -- should just be the 3 that we have manual adjustments recorded for. These have been manually changed/corrected.

```{r}
 litigant_txt %>% 
   mutate(txt_full = str_squish(txt_full),
          summary = grepl("summary of argument|summary of the argument", txt_full, ignore.case = T)) %>%
   filter(!summary) %>% 
   select(brief)
```


Add column for party

```{r}
litigant_txt <- litigant_txt %>% 
  mutate(brief_party = ifelse(grepl("\\(feminist\\)", brief, ignore.case=T), 1, 0)) %>% 
  select(case:id, brief_party, txt_full)
```

Check colnames 
```{r}
litigant_txt %>% colnames()
```


If adding cases adhoc, join now

```{r}
litigant_all <- box_read("955333134918") %>%
  filter(!(brief %in% c("Bellotti v Baird (1976). Brief for Appellees (feminist).docx",
                       "Colautti v. Franklin. Brief for Respondent (Feminist) - (labeled Beal v Franklin).pdf",
                       "Doe v. Bolton Brief for Petitioners (Feminist).pdf",
                       "Doe v. Bolton Brief for Respondents.pdf",
                       "H.L. v Matheson. Brief for Appellant (feminist).docx",
                       "United States v Vuitch. Brief for Appellant %28United States%29.docx",
                       "United States v. Vuitch. Brief for Respondent (Feminist).pdf"))) %>% 
  rbind(litigant_txt)
```



# 3. Write file to Box

```{r}
box_write(litigant_txt,
          file_name = "raw-litigant-brief-text.csv",
          dir_id = '162588272045')
```


---
title: "06-clean-data-and-frame-dict"
author: "Amanda Konet"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F, error = F)

# data manip
library(tidyverse)
library(tidytext)
library(textclean)
library(tm)
library(stringi)
library(quanteda)

# data
library(boxr)
box_auth()
```

# Purpose

To clean the amicus text and the frame dictionary for searching.

# Data

Amicus Text

```{r}
# data/processed amicus files/shortened-amicus-text-vars.csv
amicus <- box_read("946743626631", read_fun = readr::read_csv)
```

Frame terms

```{r}
# data/amicus content - frames
frames <- box_read("947237361645")
```


# Amicus Text Cleaning

Note: text is already lowercased!

1. Fix characters

```{r}
fix_chars <- function(x) {
  
  x <- gsub('â€¦', " ", x) # ellipses
  x <- gsub('â€“', "-", x) # long hyphen
  x <- gsub('â€™', "'", x) # curly apostrophe
  x <- gsub('â€œ', " ", x) # curly open quote
  x <- gsub('â€\\\u009d', " ", x) # curly closed quote
  x <- replace_white(x) # replace instances of multiple white spaces in a row
  x <- replace_curly_quote(x)
  x <- replace_non_ascii(x)
  
  return(x)
}

# call on text
amicus <- amicus %>% mutate(text_clean = fix_chars(text))
```


2. Remove URLs


```{r}
amicus <- amicus %>%
  mutate(text_clean = qdapRegex::rm_url(text_clean))
```



3. Replace Proper Names

```{r}
# proper names df
proper_names <- box_read("608071334097", read_fun = readr::read_csv) %>% 
  mutate(word = str_to_lower(word))

amicus <- amicus %>% as.data.frame()

# Replace spaces in proper names with underscores
amicus <- DataCombine::FindReplace(data = amicus, Var = "text_clean", 
                         replaceData = proper_names, 
                         from = "word", to = "replacement", exact = FALSE)
```


4. Remove instances of specific words and phrases


First, "the fact that" and "in fact"

```{r}
amicus <- amicus %>% mutate(text_clean = gsub("the fact that|in fact", "", text_clean))
```

Then, some instances of "fact" and "reports"

```{r}
amicus <- amicus %>%
  mutate(
    text_clean = case_when(
      case == "City of Akron v Akron Center" ~ 
        gsub(pattern = "fact |facts ", replacement = "", x = text_clean, ignore.case = T),
      case %in% c("PP v Ashcroft","Thornburgh v. American College of OBGYNs") ~
        gsub(pattern = "report|reports|reporting|reported", replacement = "", x = text_clean, ignore.case = T),
      TRUE ~ text_clean
    )
  )
```

5. Final tidying

Includes replacing stopwords, trimming whitespace, removing contractions, etc.

```{r}
stops <- stopwords("en")

clean_text <- function(df) {
  
  # Remove square brackets
  df$text_clean <- sapply(df$text_clean, function(x) gsub("\\[", "", x))
  df$text_clean <- sapply(df$text_clean, function(x) gsub("\\]", "", x))
  
  # Replace contractions 
  df$text_clean <- sapply(df$text_clean, function(x) replace_contraction(x, sent.cap = FALSE))
  
  # Possessive words - remove 's
  df$text_clean <- sapply(df$text_clean, function(x) gsub("'s", " ", x))
  
  # Replace hyphen with space
  df$text_clean <- sapply(df$text_clean, function(x) gsub("-", " ", x))
  
  # Remove all other punctuation
  df$text_clean <- sapply(df$text_clean, function(x) gsub("[^[:alpha:][:space:]]", " ", x))
  
  # Add space between digits & letters
  df$text_clean <- sapply(df$text_clean, function(x)
    gsub("([[:alpha:]])([[:digit:]])", "\\1 \\2", x))
  df$text_clean <- sapply(df$text_clean, function(x)
    gsub("([[:digit:]])([[:alpha:]])", "\\1 \\2", x))
  
  # Remove stop words
  df$text_clean <- sapply(df$text_clean, function(x) removeWords(x, words = stops))
  
  # Strip white space
  df$text_clean <- sapply(df$text_clean, replace_white)
  
  return(df)
  
}

amicus <- clean_text(amicus)
```

Ensure no NAs were created in this process:

```{r}
amicus %>% filter(is.na(text_clean))
```


Save

```{r}
#box_write(amicus,
#           file_name = "clean-shortened-amicus-text-vars.csv",
#           dir_id = 145990409196)
```


# Frame Terms Cleaning

1. One row per word/phrase

Currently, data is one row per frame. Expand df on comma

```{r}
frames <- frames %>% separate_rows(., word_list, sep = ",") %>% 
  mutate(frame_code = gsub(" ", "_", frame)) %>% 
  select(frame, frame_code, word = word_list) %>% 
  arrange(frame_code)

frames %>% head()
```

2. Fix characters 

```{r}
frames <- frames %>% mutate(word_clean = fix_chars(word))
```


3. Clean text & lowercase

```{r}
stops <- stopwords("en")

# The clean_text function
clean_text_frames <- function(x) {
  
  # Replace contractions 
  x <- replace_contraction(x, sent.cap = FALSE)
  
  # Posessive words - remove 's
  x <- gsub("'s", " ", x)
  
  # Replace hyphen with space
  x <- gsub("-", " ", x)
  
  # Remove stop words
  x <- removeWords(x, words = stops)
  
  # Strip white space
  x <- replace_white(x)
  
  x <- trimws(x)
  
  x <- str_to_lower(x)
  
  return(x)
}

frames <- frames %>% mutate(word_clean = clean_text_frames(word_clean))
```

4. Fix instances where multiple phrases can come from one. Ex: "physician(s)" should be physician and physicians

Create two columns 
* tense: if a phrase includes () (example: "physician(s))
* mulit: if there are multiple tenses
* slash: if contains / (ex: "wome/an")

There are only cases with parens. No multi or slash

```{r}
frames <- frames %>%
  mutate(tense = ifelse(grepl("\\(|\\/", word_clean), word_clean, ""),
         multi = ifelse(grepl("\\)\\(", word_clean), TRUE, FALSE),
         slash = ifelse(grepl("\\/", word_clean), TRUE, FALSE)
  )

frames %>% filter(tense != "") %>% nrow()
frames %>% filter(multi) %>% nrow()
frames %>% filter(slash) %>% nrow()
```

Remove multi & slash

```{r}
frames <- frames %>% select(-multi, -slash)
```


If we have a phrase like "actually further(ed) government interest", this code chunk sets the value of `tense_1` to "actually furthered government interest" and `tense_2` to "actually further government interest."

```{r}
frames <- frames %>%
  mutate(tense_1 = ifelse(tense != "", gsub("\\(|\\)", "", word_clean), ""), 
         tense_2 = ifelse(tense != "", gsub("\\([a-z]+\\)", "", tense), ""))  

# fix two errors that will arise
frames <- frames %>% 
  mutate(tense_1 = str_replace(tense_1, "uncertaintyies", "uncertainties"),
         tense_1 = str_replace(tense_1, "authorityies", "authorities"))
```


Re-apply processing on tense_1 & 2

```{r}
frames <- frames %>% mutate_at(vars(tense_1, tense_2), clean_text_frames)
```


Fix so one row per phrase

```{r}
frame_tense_1 <- frames %>% 
  filter(tense != "") %>% 
  select(frame, frame_code, word, word_clean=tense_1)

frame_tense_2 <- frames %>% 
  filter(tense != "") %>% 
  select(frame, frame_code, word, word_clean=tense_2)

frames <- frames %>% filter(tense == "") %>% select(frame, frame_code, word, word_clean)

frames <- frames %>% rbind(frame_tense_1, frame_tense_2) %>% arrange(frame, word_clean)
```


Remove any remaining punctuation

```{r}
# Remove all other punctuation
frames <- frames %>% mutate(word_clean = gsub("[^[:alpha:][:space:]]", " ", word_clean))
```


Check 

```{r}
frames <- frames %>% distinct(frame, frame_code, word_clean)
```

Save

```{r}
box_write(frames,
           file_name = "clean-amicus-iv-frame-dictionary.csv",
           dir_id = 161199725595)
```






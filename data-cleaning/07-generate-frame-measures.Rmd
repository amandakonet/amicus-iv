---
title: "Generate Frame Measures"
author: "Amanda Konet"
date: "`r Sys.Date()`"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F, error = F)
library(tidyverse)
library(tidytext)
library(textclean)
library(tm)
library(stringi)
library(quanteda)

library(boxr)
box_auth()
```


# Purpose

To develop amicus- and frame-level measures of frame usage

# Data

Abortion frame terms:

```{r}
frame_terms <- box_read("947335700912", read_fun = readr::read_csv)
```

Amicus data:

```{r}
# abortion cases
amicus <- box_read("947307207905", read_fun = readr::read_csv) %>% 
  mutate(brief_party = ifelse(id == 861815623586, 1, brief_party))
```


# Amicus-Level Measures

Start by creating corpus 


```{r}
amicus_corp <- amicus$text_clean %>% corpus()

# Add meta data to corpus
docvars(amicus_corp, "case") <- amicus$case
docvars(amicus_corp, "brief") <- amicus$brief
docvars(amicus_corp, "id") <- amicus$id
docvars(amicus_corp, "brief_party") <- amicus$brief_party

summary(amicus_corp) %>% head()
```


## Create frame dictionary

This dictionary will be used to filter out frame words from paragraphs when counting word frequency. 

```{r}
# Remove duplicates
frame_terms <- frame_terms %>%
  select(frame_code, word_clean) %>% 
  unique()

# Get words associated with frames
get_frames <- function(frame){ 
  frame_terms %>%
    filter(frame_code == frame) %>% 
    select(word_clean)
  }

# Initialize list
search_frames <- list()

# Get unique frames
frames <- unique(frame_terms$frame_code)

# Pull words for each frame and save in list
for(i in 1:length(frames)){ 
  search_frames[i] <- get_frames(frames[i])
}

# Name items in list
names(search_frames) <- frames

frame_dict <- dictionary(search_frames)

# Check output
#frame_dict
```

# Look up frames

**Note on arguments in `tokens()` function**: removing punctuation and numbers from terms increases counts. See `amicus-exploring-counting-frames` script to go over evidence. 

```{r}
# Tokenize briefs
toks <- tokens(amicus_corp, remove_punct = TRUE, remove_numbers = TRUE)
```

## Create brief summary statistics

The `amicus_corp_summary` data frame contains the summary statistics of all the briefs in our corpus, `amicus_corp`. The one thing it's missing is the number of tokens (i.e. words) in each brief. 

```{r}
# Generate summary of amicusCorp
amicus_corp_summary <- summary(object = amicus_corp, 
                      n = nrow(amicus), # default is 100, we need all observations 
                      showmeta = TRUE) %>% # add meta data to summary
  as.data.frame() 

# check
tail(amicus_corp_summary)
```


Calculate total number of words in each brief. Join with the amicus_corp_summary

```{r}
# Total number of tokens (before pulling frame words)
nToks <- data.frame(Text = names(ntoken(toks)), 
                     word_ct = ntoken(toks))

# Look at first 6 observations
head(nToks)
```

```{r}
amicus_info <- amicus_corp_summary %>%
  left_join(nToks, by = c("Text")) %>% 
  rename(doc_id=Text)

head(amicus_info)
```

## Generate frame frequencies

Now that we've created our `amicus_info` data frame, it's time to generate the frame frequencies.

(# of words/phrases for a particular frame) / (# of all words in the brief)


```{r}
# Search for frames
amicus_dfm <- tokens_lookup(toks, dictionary = frame_dict, nested_scope = "dictionary",
                         case_insensitive = FALSE, valuetype = "fixed") %>% dfm()

# Generate raw frequencies
amicus_frames_raw <- amicus_dfm %>%
  convert(to = "data.frame") %>%
  left_join(amicus_info, by = "doc_id") %>% 
  janitor::clean_names()

# Check out first 6 observations 
head(amicus_frames_raw, 10)
```

Get frame frequencies - These are calculated by dividing the frame count by the word count. 

```{r}
# Generate frame frequencies 
amicus_frames_freq <- amicus_frames_raw %>% 
  pivot_longer(c(abortion_different:womens_rights),
               names_to = "frame", values_to = "frame_ct") %>% 
  mutate(frame_freq = frame_ct/word_ct) %>% 
  select(-frame_ct, -word_ct) %>% 
  pivot_wider(names_from = "frame", values_from = frame_freq)

amicus_frames_freq %>% head(10)
```

## Raw counts + freq

Dataframe with raw counts and frequencies

```{r}
amicus_frames <- amicus_frames_raw %>% 
  select(doc_id:womens_rights, word_ct) %>% 
  left_join(., amicus_frames_freq, 
            by = c("doc_id"), 
            suffix = c("_raw", "_freq")) %>% 
  select(-c(types:sentences)) %>% 
  select(case:brief_party, word_ct, sort(colnames(.))) %>% 
  janitor::clean_names()

amicus_frames %>% head(10)
```

Save

```{r}
box_write(amicus_frames,
           file_name = "amicus-level-frame-measures.csv",
           dir_id = 161199725595)
```



# Case-Level Measures

To generate case-level measures:

1. For each amicus type, sum up the frame frequencies measure for all amicus
2. Divide by the number of briefs for that type
3. Do for all cases

```{r}
amicus_frames <- amicus_frames %>% select(-c(case, brief, brief_party))
```



## Sum up frequencies by amicus type

First, add in amicus type vars

```{r}
sum_amicus <- amicus %>% select(case, id, forgau:sgauo) %>% 
  pivot_longer(., cols = c(forgau:sgauo), names_to = "author_type", values_to = "value") %>% 
  filter(value == 1) %>% 
  left_join(., amicus_frames, by = "id") %>%
  select(case, id, author_type, value, contains("freq"))

sum_amicus %>% head()
```


Then, sum up values by case, amicus type

```{r}
sum_amicus <- sum_amicus %>% 
  select(-value) %>% 
  group_by(case, author_type) %>% 
  summarize(across(contains("freq"), ~ sum(.x, na.rm = TRUE)))

sum_amicus %>% head(5)
```


## Number of briefs per amicus author type per case

Pivot the df and select only rows where value is 1 (indicating that the case has an amicus brief with that author type)

```{r}
case_cts <- amicus %>% select(case, forgau:sgauo) %>% 
  pivot_longer(., cols = c(forgau:sgauo), names_to = "author_type", values_to = "value") %>% 
  filter(value == 1)
```

Then, group by case, type and count the number of rows for each

```{r}
case_cts <- case_cts %>% group_by(case, author_type) %>% summarize(n=n())
case_cts %>% head()
```

## Divide summed frequencies by brief count for final measure

```{r}
case_frames <- sum_amicus %>% left_join(., case_cts, by = c("case", "author_type")) %>% 
  mutate(across(contains("freq"), ~.x/n))
```


Save

```{r}
box_write(case_frames,
           file_name = "case-level-frame-measures.csv",
           dir_id = 161199725595)
```



